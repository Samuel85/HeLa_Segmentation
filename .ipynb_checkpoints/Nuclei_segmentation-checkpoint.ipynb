{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "offshore-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extraordinary-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-revision",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "different-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list,title=['DIC Image', 'User Defined Mask', 'Predicted Mask']):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])        \n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]),cmap=plt.cm.get_cmap(\"jet\"))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "def my_generator(gen1, gen2,batch_size=6,training=True):\n",
    "    while True:\n",
    "        image_batch, label_batch=next(gen1)[0], np.expand_dims(next(gen2)[0][:,:,0],axis=-1)\n",
    "        image_batch, label_batch=np.expand_dims(image_batch,axis=0),np.expand_dims(label_batch,axis=0)\n",
    "\n",
    "        for i in range(batch_size-1):\n",
    "            image_i,label_i = next(gen1)[0], np.expand_dims(next(gen2)[0][:,:,0],axis=-1)\n",
    "            \n",
    "        image_i, label_i=np.expand_dims(image_i,axis=0),np.expand_dims(label_i,axis=0)\n",
    "        image_batch=np.concatenate([image_batch,image_i],axis=0)\n",
    "        label_batch=np.concatenate([label_batch,label_i],axis=0)\n",
    "\n",
    "        yield((image_batch,label_batch))\n",
    "\n",
    "# Show predictions from the training datasets\n",
    "def show_predictions(generator=None, num=3):\n",
    "    if generator == None:        \n",
    "        generator = train_generator\n",
    "    for i in range(num):\n",
    "        image, mask=next(generator)\n",
    "        sample_image, sample_mask= image[1], mask[1]\n",
    "        image = np.expand_dims(sample_image, axis=0)\n",
    "\n",
    "        pr_mask = model.predict(image)\n",
    "        pr_mask = np.expand_dims(pr_mask[0].argmax(axis=-1),axis=-1)\n",
    "\n",
    "        display([sample_image, sample_mask,pr_mask])        \n",
    "\n",
    "# Show predictions and generate time lapses of unlabeled images\n",
    "def predict(generator=None, num=3, save=False, showplot=True):\n",
    "    unlabeled_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    unlabeled_generator = unlabeled_datagen.flow_from_directory(PATH+'test_imgs/',target_size= TARGET_SIZE,batch_size = 1,class_mode = None,shuffle=False)\n",
    "            \n",
    "    for i in range(num):        \n",
    "        image = next(unlabeled_generator)\n",
    "        mask = model.predict(image)\n",
    "        mask = np.expand_dims(mask[0].argmax(axis=-1),axis=-1)\n",
    "        \n",
    "        mask = mask * [1,1,0]\n",
    "        mask = mask + 1\n",
    "        \n",
    "        img_out = image*mask\n",
    "        \n",
    "        #Normalization\n",
    "        img_out = img_out + np.min(img_out)\n",
    "        new = (1/(np.max(img_out))) * img_out\n",
    "                             \n",
    "        if save == True:\n",
    "            plt.imsave(OUTPUT_PATH + 'out_'+str(i)+'.png', new[0])\n",
    "        if showplot==True:\n",
    "            display([img_out[0]], title=[''])\n",
    "        else:\n",
    "            print(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tamil-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/samuel/Desktop/train_n_val/'\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "LABELS=['background','nucleus','other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enormous-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nonprofit-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attached-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=['background','nucleus','other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "super-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n",
      "Found 22 images belonging to 1 classes.\n",
      "Found 17 images belonging to 1 classes.\n",
      "Found 17 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1,      \n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "val_datagen_mask = ImageDataGenerator(\n",
    "    rescale=1\n",
    ")\n",
    "\n",
    "\n",
    "#\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    PATH+'train_imgs/',\n",
    "    target_size= TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = None,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    PATH+'train_masks/',\n",
    "    target_size= TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,    \n",
    "    class_mode = None,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = val_datagen.flow_from_directory(\n",
    "    PATH+'val_imgs/',\n",
    "    target_size= TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,        \n",
    "    class_mode = None,  \n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset_mask = val_datagen_mask.flow_from_directory(\n",
    "    PATH+'val_masks/',\n",
    "    target_size= TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,    \n",
    "    class_mode = None,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "train_generator = my_generator(train_dataset, test_dataset, training=False)\n",
    "val_generator = my_generator(val_dataset, val_dataset_mask, training=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-aside",
   "metadata": {},
   "source": [
    "Update model with any other backbone and weights from the segmentation_models project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "black-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('mobilenet',\n",
    "                encoder_weights='imagenet',\n",
    "                input_shape=(None,None,3),\n",
    "                classes=len(LABELS),\n",
    "                activation='softmax',                 \n",
    "                encoder_freeze = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "terminal-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy',sm.metrics.IOUScore(threshold=0.5)],\n",
    "              loss_weights=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intended-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4931: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 10s 113ms/step - loss: 0.7645 - accuracy: 0.3236 - iou_score: 0.2209 - val_loss: 7.7620 - val_accuracy: 0.3778 - val_iou_score: 0.1810\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0948 - accuracy: 0.6159 - iou_score: 0.3206 - val_loss: 1.0998 - val_accuracy: 0.5417 - val_iou_score: 0.2394\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.0489 - accuracy: 0.6202 - iou_score: 0.3252 - val_loss: 1.0191 - val_accuracy: 0.5146 - val_iou_score: 0.2301\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.0360 - accuracy: 0.6161 - iou_score: 0.3268 - val_loss: 0.6677 - val_accuracy: 0.5490 - val_iou_score: 0.2474\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0306 - accuracy: 0.6191 - iou_score: 0.3276 - val_loss: 0.7063 - val_accuracy: 0.5350 - val_iou_score: 0.2415\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0290 - accuracy: 0.6153 - iou_score: 0.3277 - val_loss: 0.2478 - val_accuracy: 0.6214 - val_iou_score: 0.2875\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0295 - accuracy: 0.6167 - iou_score: 0.3272 - val_loss: 0.2204 - val_accuracy: 0.6249 - val_iou_score: 0.2878\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.0249 - accuracy: 0.6170 - iou_score: 0.3285 - val_loss: 0.2466 - val_accuracy: 0.6278 - val_iou_score: 0.2873\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0216 - accuracy: 0.6183 - iou_score: 0.3292 - val_loss: 0.2223 - val_accuracy: 0.6338 - val_iou_score: 0.2893\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.0224 - accuracy: 0.6179 - iou_score: 0.3288 - val_loss: 0.1784 - val_accuracy: 0.6596 - val_iou_score: 0.2976\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0205 - accuracy: 0.6150 - iou_score: 0.3295 - val_loss: 0.1762 - val_accuracy: 0.6512 - val_iou_score: 0.2978\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.0199 - accuracy: 0.6149 - iou_score: 0.3294 - val_loss: 0.1241 - val_accuracy: 0.6558 - val_iou_score: 0.3060\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.0184 - accuracy: 0.6158 - iou_score: 0.3298 - val_loss: 0.1190 - val_accuracy: 0.6657 - val_iou_score: 0.3078\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0172 - accuracy: 0.6196 - iou_score: 0.3303 - val_loss: 0.1196 - val_accuracy: 0.6692 - val_iou_score: 0.3079\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.0167 - accuracy: 0.6166 - iou_score: 0.3302 - val_loss: 0.1208 - val_accuracy: 0.6745 - val_iou_score: 0.3096\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.0158 - accuracy: 0.6152 - iou_score: 0.3303 - val_loss: 0.1107 - val_accuracy: 0.6746 - val_iou_score: 0.3123\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.0160 - accuracy: 0.6139 - iou_score: 0.3302 - val_loss: 0.1363 - val_accuracy: 0.6706 - val_iou_score: 0.3058\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.0142 - accuracy: 0.6128 - iou_score: 0.3311 - val_loss: 0.1622 - val_accuracy: 0.6734 - val_iou_score: 0.3033\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0133 - accuracy: 0.6163 - iou_score: 0.3312 - val_loss: 0.1412 - val_accuracy: 0.6770 - val_iou_score: 0.3073\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0131 - accuracy: 0.6126 - iou_score: 0.3312 - val_loss: 0.1265 - val_accuracy: 0.6708 - val_iou_score: 0.3074\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0119 - accuracy: 0.6186 - iou_score: 0.3315 - val_loss: 0.1082 - val_accuracy: 0.6741 - val_iou_score: 0.3113\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.0116 - accuracy: 0.6174 - iou_score: 0.3315 - val_loss: 0.1381 - val_accuracy: 0.6757 - val_iou_score: 0.3085\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.0114 - accuracy: 0.6176 - iou_score: 0.3315 - val_loss: 0.1229 - val_accuracy: 0.6829 - val_iou_score: 0.3121\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0108 - accuracy: 0.6158 - iou_score: 0.3315 - val_loss: 0.1401 - val_accuracy: 0.6910 - val_iou_score: 0.3102\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0130 - accuracy: 0.6130 - iou_score: 0.3310 - val_loss: 0.1320 - val_accuracy: 0.6783 - val_iou_score: 0.3069\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.0121 - accuracy: 0.6174 - iou_score: 0.3312 - val_loss: 0.2168 - val_accuracy: 0.6716 - val_iou_score: 0.2979\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0095 - accuracy: 0.6154 - iou_score: 0.3319 - val_loss: 0.1719 - val_accuracy: 0.6784 - val_iou_score: 0.3040\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.0091 - accuracy: 0.6183 - iou_score: 0.3321 - val_loss: 0.1725 - val_accuracy: 0.6820 - val_iou_score: 0.3055\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.0079 - accuracy: 0.6179 - iou_score: 0.3323 - val_loss: 0.1717 - val_accuracy: 0.6879 - val_iou_score: 0.3066\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.0080 - accuracy: 0.6198 - iou_score: 0.3323 - val_loss: 0.1669 - val_accuracy: 0.6817 - val_iou_score: 0.3080\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "STEPS_PER_EPOCH = 30\n",
    "VALIDATION_STEPS = 10\n",
    "\n",
    "model_history = model.fit(train_generator,\n",
    "                          epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_data=val_generator,\n",
    "                          validation_steps=VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "temporal-quality",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3289b78a591e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/samuel/Desktop/191017/'\n",
    "\n",
    "OUTPUT_PATH = '/home/samuel/Desktop/ccc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    " predict(generator=None, num=14, save=False, showplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
